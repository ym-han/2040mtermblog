{
  
    
        "post0": {
            "title": "Post 2 of 3",
            "content": "This is the second of the blog posts for our midterm project in Data 2040, a deep learning class at Brown University. As quick reminder, the first blog post can be accessed here. . We explored 3 architectures for this prediction task: ResNET, InceptionNet, and EfficientNet. As we’ll see, the EfficientNet model ended up having the highest accuracy. . The ResNET model (a tweaked version of our second baseline model) . One simple approach we took to build upon our second, and more sophisticated, baseline model; this was a (slightly) finetuned version of a ResNET50 model, courtesy of Zach Mueller. . Since we’ve already explained the rough contours of the model in our previous blog post, we won’t spend much time here talking about we did the previous round. That said, it’s worth briefly explaining the ResNET architecture. . What is the ResNET architecture . This was invented by Kaiming He et al in 2015; the key innovation, at the risk of over-simplifying, was to use so-called ‘skip connections’ — connections between layers that skip over layers — that make deeper networks easier to train. (For more details, see either the original paper, or FastAI’s explanations of it. . What we did this time . As we’d mentioned in the previous blogpost, the model was implemented using the FastAI library. Although our previous version of the model employed some data augmentation, we’d confined ourselves to the basic ones that are already built into FastAI; our main experiment this time was to try doing even more data augmentation with albumentations library (by adapting another one of Mueller’s notebooks). In particular, we added transforms like hue and saturation tweaks, as well as ‘cutout’ and ‘coarse dropout’. The last two are worth emphasizing: they basically involve randomly remove rectangles from the image during training (cutout removes one large but otherwise randomly sized square, whereas coarse dropout removes many small similarly-sized rectangles). . Adding these augmentations turned out to be more effective than we’d had expected. This model had already got to 79% validation accuracy with just 1 frozen epoch and 3 epochs, even before adding these more sophisticated augmentations; after adding them, we got to 84% accuracy (with the same number of epochs). That’s a big difference, for not very much work. . . But why, you might ask, did adding these augmentations make such a big difference? We speculate that it’s because these augmentations — as with any sort of data augmentation — serve to regularize the model, preventing it from overfitting to the training data. (This, of course, doesn’t yet answer why it made such a big difference. But trying to answer that would bring us too far afield.) . Links / resources / references . Our Colab notebook for both the baseline and tweaked model can be found here. | Again, in making this notebook, we adapted two of Zach Mueller’s notebooks: https://www.kaggle.com/muellerzr/cassava-fastai-starter and https://www.kaggle.com/muellerzr/recreating-abhishek-s-tez-with-fastai | Here’s the paper that introduced ResNET to the world. | And the paper on cutout can be found here | . EfficientNet model . The second architecture we tried was EfficientNet, via this notebook. . EfficientNet architecture . EfficientNet uses the compound-scaling(balancing dimensions of the width, depth, and resolution by scaling up them with a constant ratio) method to heuristic scale-up convolution neural networks (Tan and Le, 2019) to avoid computational expensive grid-search of hyperparameter. There is a family of EfficientNet models that makes up a good combination of efficiency and accuracy on various scales. Keras API provides pre-trained EfficientNet models with different variants from B0 to B7. The input shape is different for each of these variants. . What we did . We implemented the pre-trained EfficientNetB3 model based on the input image resolution. On top of the pre-trained EfficientNetB3 model, we first did global average pooling. Then we added a dense layer with 256 neurons, with an activation function of Relu, followed by a dropout layer with a dropout rate of 0.5. Finally a dense output layer with softmax activation function with 5 neurons. The model architecture looks like this: . . We implemented Early Stopping and ReduceLROnPlateau callbacks in the model. The early stopping callback stop training once a monitored metric has stopped improving. In our case, the monitored metric is validation loss. The model training loop will check at the end of every epoch if the validation loss is no longer decreasing based on some user-customized criteria. For example, in our model, we set min_delta = 0.001, which is the minimum change in the validation loss we set to qualify as an improvement, and patience = 7, the number of epochs with no improvement after which training will be stopped. Once the model training loop found the validation loss is no longer decreasing based upon these criteria, the training will terminate. Similarly, the ReduceLROnPlateau callback reduces the learning rate when the monitored metric stopped improving. Many models would benefit from reducing the learning rate by a factor of 2-10 once learning stopped. It allows us to monitor the metric we are interested in; and if we see no improvement for patience (we set to 2) number of epochs, the learning rate will be reduced. . We used the Adam optimizer, the categorical cross-entropy with 0.3 label smoothing was used given there is some mislabelling in the dataset. We split the data 80% for training, 20% for testing. We set to train the model for 30 epochs but it stopped early at 24 epochs since the early stopping criteria has been met. Finally, the model achieved an accuracy of around 89%. . Train and validation loss and accuracy figures are shown below: . . Resources / references . Tan and Le,2019. https://arxiv.org/pdf/1905.11946.pdf . Keras’ tutorial on fine-tuning Efficient Net . Inception . The third model we tried is inception-v3 pre-trained on ImageNet. Compared to EfficientNet, it performs slightly worse on ImageNet and on the Cassava dataset. It gave a validation/testing accuracy of 84%. Inception-v3 is the third version of Google’s inception network series (googlenet/inception) and is proven to be significantly computationally efficient. . Inception v3 Architecture . The architecture of an Inception v3 network is progressively built, step-by-step, as follows: . Factorized convolutions to reduce parameters | Smaller convolutions | Asymmetric convolution | Auxiliary classifier: an auxiliary classifier is a small CNN inserted between layers during training, and the loss incurred is added to the main network loss | Grid size reduction | For the head of the model we added a dropout layer and a dense softmax layer with 5 neurons. The optimizer used was SGD and loss was CategoricalCrossEntropy with 0.2 label smoothing. The label smoothing is because there is some amount of mislabelling in the dataset. The base notebook we used also used Xception for the base model, however since there were very small differences in the validation accuracy and loss, we chose to keep Inception-v3 as our 3rd model. . We tried training with multiple epochs but there was no significant increase in val. accuracy after 8 epochs (as in the original notebook) and since every epoch took upwards of 10 minutes for us, in the interest of time we kept it at 8. The validation accuracy we got in the end was 84%. . Resources / references . Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., &amp; Rabinovich, A. (2014). Going deeper with convolutions. . Vihar Kurama. (2020, June 5). A Guide to ResNet, Inception v3, and SqueezeNet Paperspace Blog. Paperspace Blog; Paperspace Blog. . Jun Ying’s Kaggle notebook . Bergman A, Lindell D. Factorized Convolution Kernels in Image Processing. Accessed March 16, 2021. . Conclusion . We’ve seen how EfficientNet got the best accuracy of the three architectures. Although this obviously wasn’t a carefully controlled comparison — there were a thousand and one variables that we didn’t control — it’s at least suggestive, especially in light of how the best-performing teams on this Kaggle competition also used EfficientNet. . What further steps will we take? Perhaps the most obvious, in light of our discussion, is: use EffficientNet! Less obviously, but more importantly, since at least some of our experiments were performed on imbalanced validation data sets, we also want to try seeing how our models perform with more balanced ones (c.f. our teacher Bo Qing’s comments on another group’s work during office hours). We also hope to carry out more experiments with data augmentation, and of course do the almost-obligatory hyperparameter tuning. Finally, we have a bunch of snazzy model interpretability visualizations lined up, so stay tuned! .",
            "url": "https://ym-han.github.io/2040mtermblog/markdown/2020/03/15/post2.html",
            "relUrl": "/markdown/2020/03/15/post2.html",
            "date": " • Mar 15, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ym-han.github.io/2040mtermblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Us",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ym-han.github.io/2040mtermblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ym-han.github.io/2040mtermblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}